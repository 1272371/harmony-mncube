![](teraflow.webp)
# Prove that you are a Super Charged Data Engineer!

Submit a pull request from your own fork to this repo, to super-charge your Data Engineer job application at Teraflow.

## The brief

You are consulting on new Cryptocurrency Trading start-up __*CryptoDudez*__'s Machine Learning project.

![](ethereum.jpg)

They would like to automate their Ethereum trades by making use of machine learning on a scalable and cost-effective cloud solution on either AWS or GCP and require your help in scoping out the solution architecture, as well as building a minimal proof of concept solution within 7 days.

## The data

__*CryptoDudez*__ have made use of some interns to gather historical crypto prices and have provided this to you in the archive: `cryptocurrency_historical_prices.zip`.

They have also gathered some of Elon Musk's historical tweets in the archive `elon_musk_tweets.zip` and stock market tickers in the archive `stock_prices_2020_2021.zip`

Their ultimate goal is to train an ML model which will predict whether to buy, sell or [HODL](https://www.nerdwallet.com/article/investing/hodl-a-typo-takes-hold-as-a-sound-cryptocurrency-strategy) their current Ethereum stockpile. But before any fancy Machine Learning work can commence, they need some serious Data Engineering know-how to get their environment ready to enable this AI use-case.

## The requirements

__*CryptoDudez*__ would like the cryptocurrency data, as well as any additional datasources to be stored in their raw form on a Data Lake layer.

Upon landing in the data lake, an automated process should be kicked off which runs various data validation checks, as well as performs some basic transformations, such as converting data to parquet format.

We usually scope out our project requirements in a Sprint Zero phase, where we usually come up with some solution diagrams, we'd like you to draw up an architectural diagram for your solution before you start.
